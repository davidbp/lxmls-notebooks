{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Exercise | Requires coding | What to code (if anything) | What should you learn (or practice)    | Done it! |\n",
    "|----------|-----------------|----------------------------|----------------------------------------|----------|\n",
    "| 5.1      | Yes             |    Backpropagation                         | Backprop details                           | No       |\n",
    "| 5.2      | No              |                            | Familiarize with theano                           | No       |\n",
    "| 5.3      |   Yes         |   Forward pass MLP                            | Symbolic forward pass                                | No       |\n",
    "| 5.4      |   No         |        | check TheanoMLP  class                           | No       |\n",
    "| 5.5      |   No         |        | Data in theano (shared variables)                                | No       |\n",
    "| 5.6      |   No         |        | Compare Numpy vs Theano                                | No       |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../lxmls-toolkit')\n",
    "import lxmls\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ecxercise 5.1\n",
    "\n",
    "**Start by loading Amazon sentiment corpus used in day 1**\n",
    "\n",
    "Go to **lxmls/deep\\_learning/mlp.py** look at the class NumpyMLP and the function ** grads( )**. Complete the\n",
    "code of the NumpyMLP class with the Backpropagation recursion that we just saw.\n",
    "Once you are done. Try different network geometries by increasing the number of\n",
    "layers and layer sizes e.g.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lxmls.readers.sentiment_reader as srs\n",
    "scr = srs.SentimentCorpus(\"books\")\n",
    "train_x = scr.train_X.T\n",
    "train_y = scr.train_y[:, 0]\n",
    "test_x = scr.test_X.T\n",
    "test_y = scr.test_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13989, 1600)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (13989, 1600)\n",
      "\n",
      "train matrix: \n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "test shape:  (13989, 1600)\n",
      "\n",
      "test matrix: \n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print \"train shape: \", train_x.shape\n",
    "print \"\\ntrain matrix: \\n\", train_x\n",
    "\n",
    "print \"\\ntest shape: \", train_x.shape\n",
    "print \"\\ntest matrix: \\n\", train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network modules\n",
    "import lxmls.deep_learning.mlp as dl\n",
    "import lxmls.deep_learning.sgd as sgd\n",
    "# Model parameters\n",
    "geometry = [train_x.shape[0], 20, 2]\n",
    "actvfunc = ['sigmoid', 'softmax']\n",
    "# Instantiate model\n",
    "mlp = dl.NumpyMLP(geometry, actvfunc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxmls.deep_learning.mlp.NumpyMLP instance at 0x121374638>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the gradinet\n",
    "### Check the picky monitor in your room\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 13989)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.T[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.T[0:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), array([[ 0.15625701],\n",
       "        [-0.09786025],\n",
       "        [-0.15450764],\n",
       "        [ 0.03005986],\n",
       "        [ 0.18751073],\n",
       "        [-0.00744249],\n",
       "        [ 0.23713359],\n",
       "        [ 0.04705822],\n",
       "        [ 0.25065633],\n",
       "        [ 0.10883962],\n",
       "        [-0.10858945],\n",
       "        [ 0.0331292 ],\n",
       "        [-0.10112688],\n",
       "        [-0.04554892],\n",
       "        [ 0.18257095],\n",
       "        [-0.06113073],\n",
       "        [-0.08824167],\n",
       "        [-0.04884439],\n",
       "        [-0.15747077],\n",
       "        [ 0.17085413]]), array([[ 0.19311909,  0.18508641,  0.10107927,  0.23163937,  0.18767203,\n",
       "          0.14125292,  0.22078412,  0.17063859,  0.1744801 ,  0.22629859,\n",
       "          0.13949098,  0.10196529,  0.15597426,  0.25534403,  0.16639538,\n",
       "          0.21191046,  0.17812024,  0.12184779,  0.14660312,  0.11722191],\n",
       "        [-0.19311909, -0.18508641, -0.10107927, -0.23163937, -0.18767203,\n",
       "         -0.14125292, -0.22078412, -0.17063859, -0.1744801 , -0.22629859,\n",
       "         -0.13949098, -0.10196529, -0.15597426, -0.25534403, -0.16639538,\n",
       "         -0.21191046, -0.17812024, -0.12184779, -0.14660312, -0.11722191]]), array([[ 0.36181763],\n",
       "        [-0.36181763]])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.grads(train_x.T[0:5].T,train_y.T[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlp.grads(train_x.T[0:5].T,train_y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13989)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.grads(train_x.T[0:5].T,train_y[0:5])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.grads(train_x.T[0:5].T,train_y[0:5])[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 20)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.grads(train_x.T[0:5].T,train_y[0:5])[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.grads(train_x.T[0:5].T,train_y[0:5])[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model parameters\n",
    "n_iter = 5\n",
    "bsize  = 5\n",
    "lrate  = 0.01\n",
    "# Train\n",
    "sgd.SGD_train(mlp, n_iter, bsize=bsize, lrate=lrate, train_set=(train_x, train_y))\n",
    "acc_train = sgd.class_acc(mlp.forward(train_x), train_y)[0]\n",
    "acc_test  = sgd.class_acc(mlp.forward(test_x), test_y)[0]\n",
    "print \"MLP (%s) Amazon Sentiment Accuracy train: %f test: %f\" % (geometry, acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> /Users/davidbuchacaprats/Documents/git_stuff/lxmls-toolkit/lxmls/deep_learning/mlp.py(109)grads()\n",
      "-> nabla_params = [None] * (2*self.n_layers)\n",
      "(Pdb) x.shape\n",
      "(13989, 1)\n",
      "(Pdb) activations[0].shape\n",
      "(200, 1)\n",
      "(Pdb) activations[1].\n",
      "*** SyntaxError: invalid syntax (<stdin>, line 1)\n",
      "(Pdb) activations[1].shape\n",
      "(2, 1)\n",
      "(Pdb) activations[2]\n",
      "*** IndexError: list index out of range\n",
      "(Pdb) activations\n",
      "[array([[ 0.31979048],\n",
      "       [ 0.31603868],\n",
      "       [ 0.56333396],\n",
      "       [ 0.34067588],\n",
      "       [ 0.67935699],\n",
      "       [ 0.51089186],\n",
      "       [ 0.62033117],\n",
      "       [ 0.69807076],\n",
      "       [ 0.53882517],\n",
      "       [ 0.39486335],\n",
      "       [ 0.67488142],\n",
      "       [ 0.18610934],\n",
      "       [ 0.37784234],\n",
      "       [ 0.6428463 ],\n",
      "       [ 0.45602409],\n",
      "       [ 0.47892799],\n",
      "       [ 0.65352417],\n",
      "       [ 0.16601765],\n",
      "       [ 0.40688267],\n",
      "       [ 0.43862264],\n",
      "       [ 0.53205153],\n",
      "       [ 0.62330709],\n",
      "       [ 0.47261148],\n",
      "       [ 0.74423511],\n",
      "       [ 0.23949824],\n",
      "       [ 0.72885098],\n",
      "       [ 0.33609125],\n",
      "       [ 0.19687668],\n",
      "       [ 0.3108264 ],\n",
      "       [ 0.35762205],\n",
      "       [ 0.55168214],\n",
      "       [ 0.39499817],\n",
      "       [ 0.55588628],\n",
      "       [ 0.3729787 ],\n",
      "       [ 0.53057199],\n",
      "       [ 0.30481721],\n",
      "       [ 0.5565508 ],\n",
      "       [ 0.41392975],\n",
      "       [ 0.30823655],\n",
      "       [ 0.64870189],\n",
      "       [ 0.38331844],\n",
      "       [ 0.5071918 ],\n",
      "       [ 0.65672597],\n",
      "       [ 0.50494836],\n",
      "       [ 0.33285683],\n",
      "       [ 0.27699871],\n",
      "       [ 0.36783515],\n",
      "       [ 0.26944409],\n",
      "       [ 0.49204188],\n",
      "       [ 0.68372282],\n",
      "       [ 0.37466849],\n",
      "       [ 0.49968933],\n",
      "       [ 0.63538683],\n",
      "       [ 0.4482309 ],\n",
      "       [ 0.50979204],\n",
      "       [ 0.68497448],\n",
      "       [ 0.53833418],\n",
      "       [ 0.55722513],\n",
      "       [ 0.5243797 ],\n",
      "       [ 0.4184868 ],\n",
      "       [ 0.39246404],\n",
      "       [ 0.8103724 ],\n",
      "       [ 0.54276   ],\n",
      "       [ 0.65747297],\n",
      "       [ 0.14717814],\n",
      "       [ 0.45073   ],\n",
      "       [ 0.31327836],\n",
      "       [ 0.40110712],\n",
      "       [ 0.2194591 ],\n",
      "       [ 0.58506261],\n",
      "       [ 0.56593873],\n",
      "       [ 0.72724042],\n",
      "       [ 0.53790354],\n",
      "       [ 0.42702017],\n",
      "       [ 0.27362244],\n",
      "       [ 0.53149147],\n",
      "       [ 0.28125789],\n",
      "       [ 0.73010279],\n",
      "       [ 0.15746239],\n",
      "       [ 0.43213209],\n",
      "       [ 0.57869492],\n",
      "       [ 0.18778328],\n",
      "       [ 0.39824326],\n",
      "       [ 0.39442321],\n",
      "       [ 0.58949889],\n",
      "       [ 0.47717282],\n",
      "       [ 0.54965146],\n",
      "       [ 0.68898615],\n",
      "       [ 0.39256345],\n",
      "       [ 0.59019903],\n",
      "       [ 0.30254512],\n",
      "       [ 0.24508289],\n",
      "       [ 0.53245255],\n",
      "       [ 0.61175622],\n",
      "       [ 0.57636332],\n",
      "       [ 0.5422397 ],\n",
      "       [ 0.3903621 ],\n",
      "       [ 0.37366319],\n",
      "       [ 0.50403933],\n",
      "       [ 0.29845009],\n",
      "       [ 0.71273951],\n",
      "       [ 0.28994784],\n",
      "       [ 0.42040152],\n",
      "       [ 0.62721479],\n",
      "       [ 0.53623656],\n",
      "       [ 0.32657883],\n",
      "       [ 0.63704518],\n",
      "       [ 0.5272616 ],\n",
      "       [ 0.75072023],\n",
      "       [ 0.47755492],\n",
      "       [ 0.7581727 ],\n",
      "       [ 0.53049253],\n",
      "       [ 0.50540713],\n",
      "       [ 0.38666622],\n",
      "       [ 0.5188045 ],\n",
      "       [ 0.43030003],\n",
      "       [ 0.51014464],\n",
      "       [ 0.42600756],\n",
      "       [ 0.54675843],\n",
      "       [ 0.8037039 ],\n",
      "       [ 0.43127373],\n",
      "       [ 0.33894458],\n",
      "       [ 0.38814912],\n",
      "       [ 0.6491182 ],\n",
      "       [ 0.63509943],\n",
      "       [ 0.53820422],\n",
      "       [ 0.26567253],\n",
      "       [ 0.48056156],\n",
      "       [ 0.46207477],\n",
      "       [ 0.75099814],\n",
      "       [ 0.54602765],\n",
      "       [ 0.49009754],\n",
      "       [ 0.4002526 ],\n",
      "       [ 0.32886847],\n",
      "       [ 0.52557558],\n",
      "       [ 0.54982512],\n",
      "       [ 0.53652813],\n",
      "       [ 0.50321666],\n",
      "       [ 0.4914675 ],\n",
      "       [ 0.73843435],\n",
      "       [ 0.50075417],\n",
      "       [ 0.40207351],\n",
      "       [ 0.51305131],\n",
      "       [ 0.35045975],\n",
      "       [ 0.50447299],\n",
      "       [ 0.69837381],\n",
      "       [ 0.55948863],\n",
      "       [ 0.47408069],\n",
      "       [ 0.37952789],\n",
      "       [ 0.64802252],\n",
      "       [ 0.3080021 ],\n",
      "       [ 0.52585608],\n",
      "       [ 0.52679057],\n",
      "       [ 0.73170008],\n",
      "       [ 0.38583557],\n",
      "       [ 0.25118334],\n",
      "       [ 0.38579175],\n",
      "       [ 0.73215216],\n",
      "       [ 0.69403537],\n",
      "       [ 0.38340574],\n",
      "       [ 0.6732553 ],\n",
      "       [ 0.33272689],\n",
      "       [ 0.56372071],\n",
      "       [ 0.45576183],\n",
      "       [ 0.38353794],\n",
      "       [ 0.58227751],\n",
      "       [ 0.26590364],\n",
      "       [ 0.4736611 ],\n",
      "       [ 0.39591617],\n",
      "       [ 0.58791049],\n",
      "       [ 0.61200324],\n",
      "       [ 0.63749493],\n",
      "       [ 0.24986308],\n",
      "       [ 0.31010185],\n",
      "       [ 0.57326874],\n",
      "       [ 0.29644959],\n",
      "       [ 0.36671404],\n",
      "       [ 0.31665502],\n",
      "       [ 0.60277722],\n",
      "       [ 0.40923476],\n",
      "       [ 0.41257565],\n",
      "       [ 0.52076832],\n",
      "       [ 0.4572605 ],\n",
      "       [ 0.59225041],\n",
      "       [ 0.54841102],\n",
      "       [ 0.40850977],\n",
      "       [ 0.48966726],\n",
      "       [ 0.58090101],\n",
      "       [ 0.42054313],\n",
      "       [ 0.34426375],\n",
      "       [ 0.41032135],\n",
      "       [ 0.85089545],\n",
      "       [ 0.50399189],\n",
      "       [ 0.60433699],\n",
      "       [ 0.18959649],\n",
      "       [ 0.66265967],\n",
      "       [ 0.64949002],\n",
      "       [ 0.72070969],\n",
      "       [ 0.57560825],\n",
      "       [ 0.60355454]]), array([[ 0.05831504],\n",
      "       [ 0.94168496]])]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-9cb044621b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0macc_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/Documents/git_stuff/lxmls-toolkit/lxmls/deep_learning/sgd.pyc\u001b[0m in \u001b[0;36mSGD_train\u001b[0;34m(model, n_iter, bsize, lrate, train_set, batch_up, n_batch, devel_set, model_dbg)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;31m# Update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mbatch_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;31m# INFO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\rBatch %d/%d (%d%%) \"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/Documents/git_stuff/lxmls-toolkit/lxmls/deep_learning/sgd.pyc\u001b[0m in \u001b[0;36mbatch_up\u001b[0;34m(batch_x, batch_y)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Get gradients for each layer and this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Get gradients for each layer and this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mnabla_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Update each parameter with SGD rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/Documents/git_stuff/lxmls-toolkit/lxmls/deep_learning/mlp.py\u001b[0m in \u001b[0;36mgrads\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# For each layer in reverse store the gradients for each parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnabla_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Get weigths and bias (always in even and odd positions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/Documents/git_stuff/lxmls-toolkit/lxmls/deep_learning/mlp.py\u001b[0m in \u001b[0;36mgrads\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# For each layer in reverse store the gradients for each parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnabla_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Get weigths and bias (always in even and odd positions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36muser_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_mainpyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/cmd.pyc\u001b[0m in \u001b[0;36mcmdloop\u001b[0;34m(self, intro)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rawinput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EOF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidbuchacaprats/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "n_iter = 2\n",
    "bsize  = 1\n",
    "lrate  = 0.01\n",
    "\n",
    "# Neural network modules\n",
    "import lxmls.deep_learning.mlp as dl\n",
    "import lxmls.deep_learning.sgd as sgd\n",
    "# Model parameters\n",
    "geometry = [train_x.shape[0], 200, 2]\n",
    "actvfunc = ['sigmoid', 'softmax']\n",
    "# Instantiate model\n",
    "mlp = dl.NumpyMLP(geometry, actvfunc) \n",
    "\n",
    "# Train\n",
    "sgd.SGD_train(mlp, n_iter, bsize=bsize, lrate=lrate, train_set=(train_x, train_y))\n",
    "acc_train = sgd.class_acc(mlp.forward(train_x), train_y)[0]\n",
    "acc_test  = sgd.class_acc(mlp.forward(test_x), test_y)[0]\n",
    "print \"MLP (%s) Amazon Sentiment Accuracy train: %f test: %f\" % (geometry, acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Changing architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 320/320 (100%)   Epoch  1/ 5 in 27.01 seg\n",
      "Batch 320/320 (100%)   Epoch  2/ 5 in 27.10 seg\n",
      "Batch 320/320 (100%)   Epoch  3/ 5 in 28.01 seg\n",
      "Batch 320/320 (100%)   Epoch  4/ 5 in 27.65 seg\n",
      "Batch 320/320 (100%)   Epoch  5/ 5 in 28.37 seg\n",
      " \n",
      "MLP ([13989, 40, 40, 2]) Amazon Sentiment Accuracy train: 0.936875 test: 0.785000\n"
     ]
    }
   ],
   "source": [
    "### Making bigger net\n",
    "\n",
    "# Neural network modules\n",
    "import lxmls.deep_learning.mlp as dl\n",
    "import lxmls.deep_learning.sgd as sgd\n",
    "# Model parameters\n",
    "geometry = [train_x.shape[0], 40,40, 2]\n",
    "actvfunc = ['sigmoid','sigmoid', 'softmax'] \n",
    "# Instantiate model\n",
    "mlp = dl.NumpyMLP(geometry, actvfunc) \n",
    "\n",
    "# Model parameters\n",
    "n_iter = 5\n",
    "bsize  = 5\n",
    "lrate  = 0.01\n",
    "# Train\n",
    "sgd.SGD_train(mlp, n_iter, bsize=bsize, lrate=lrate, train_set=(train_x, train_y))\n",
    "acc_train = sgd.class_acc(mlp.forward(train_x), train_y)[0]\n",
    "acc_test  = sgd.class_acc(mlp.forward(test_x), test_y)[0]\n",
    "print \"MLP (%s) Amazon Sentiment Accuracy train: %f test: %f\" % (geometry, acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 320/320 (100%)   Epoch  1/ 5 in 27.59 seg\n",
      "Batch 320/320 (100%)   Epoch  2/ 5 in 24.97 seg\n",
      "Batch 320/320 (100%)   Epoch  3/ 5 in 26.21 seg\n",
      "Batch 320/320 (100%)   Epoch  4/ 5 in 24.75 seg\n",
      "Batch 320/320 (100%)   Epoch  5/ 5 in 25.20 seg\n",
      " \n",
      "MLP ([13989, 40, 40, 2]) Amazon Sentiment Accuracy train: 0.986875 test: 0.800000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model parameters\n",
    "n_iter = 5\n",
    "bsize  = 5\n",
    "lrate  = 0.01\n",
    "# Train\n",
    "sgd.SGD_train(mlp, n_iter, bsize=bsize, lrate=lrate, train_set=(train_x, train_y))\n",
    "acc_train = sgd.class_acc(mlp.forward(train_x), train_y)[0]\n",
    "acc_test  = sgd.class_acc(mlp.forward(test_x), test_y)[0]\n",
    "print \"MLP (%s) Amazon Sentiment Accuracy train: %f test: %f\" % (geometry, acc_train,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.2 \n",
    "#### Begin Exercise 5.2\n",
    "\n",
    "Get in contact with Theano. Learn the difference between a symbolic\n",
    "representation and a function. Start by implementing the first layer of our\n",
    "previous MLP in Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy code\n",
    "x        = test_x             # Test set \n",
    "W1, b1   = mlp.params[:2]     # Weights and bias of fist layer \n",
    "z1       = np.dot(W1, x) + b1 # Linear transformation\n",
    "tilde_z1 = 1/(1+np.exp(-z1))  # Non-linear transformation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Theano code. \n",
    "# NOTE: We use undescore to denote symbolic equivalents to Numpy variables. \n",
    "# This is no Python convention!.\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "_x = T.matrix('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this variable does not have any particular value, nor a space\n",
    "reserved in memory for it. It contains just a symbolic definition of what the\n",
    "variable can contain. The particular values will be given when we use it to\n",
    "compile a function. \n",
    "\n",
    "We could actually use the same definition format to define the weights and give\n",
    "their particular values as inputs to the compiled function. However, since we\n",
    "will be using a more complicated format in later exercises, we will use it here\n",
    "as well. The **```shared```** class allows to define variables that are shared\n",
    "across functions. They are also given a concrete value so that we do not need\n",
    "to give it for each function call. This format is therefore ideal for the\n",
    "weights of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_W1 = theano.shared(value=W1, name='W1', borrow=True) \n",
    "_b1 = theano.shared(value=b1, name='b1', borrow=True, broadcastable=(False, True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets describe the operations we want to do with the variables. Again only\n",
    "symbolically. This is done by replacing our usual operations by Theano symbolic\n",
    "ones when necessary e. g. the internal product dot() or the sigmoid. Some\n",
    "operations like e.g. $+$ are automatically recognized by Theano (operator\n",
    "overloading). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_z1            = T.dot(_W1, _x) + _b1\n",
    "_tilde_z1      = T.nnet.sigmoid(_z1)\n",
    "# Keep in mind that naming variables is useful when debugging\n",
    "_z1.name       = 'z1'\n",
    "_tilde_z1.name = 'tilde_z1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When debugging the code it is often useful to print the graph of computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid [@A] 'tilde_z1'   \n",
      " |Elemwise{add,no_inplace} [@B] 'z1'   \n",
      "   |dot [@C] ''   \n",
      "   | |W1 [@D]\n",
      "   | |x [@E]\n",
      "   |b1 [@F]\n"
     ]
    }
   ],
   "source": [
    "# Perceptron computation graph\n",
    "theano.printing.debugprint(_tilde_z1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to keep in mind that, until this point, we do not have a\n",
    "function we can use to produce any practical input. In order to obtain this we\n",
    "have to compile this function by calling    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = theano.function([_x], _tilde_z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of [ ] for the input variables, even if we just specify one\n",
    "variable. We can now do a test to compare the Numpy and Theano implementations\n",
    "and see that they give the same outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numpy and Theano Perceptrons are equivalent\n"
     ]
    }
   ],
   "source": [
    "# Check Numpy and Theano match\n",
    "if np.allclose(tilde_z1, layer1(x.astype(theano.config.floatX))):\n",
    "    print \"\\nNumpy and Theano Perceptrons are equivalent\"\n",
    "else:\n",
    "    raise ValueError, \"Numpy and Theano Perceptrons are different\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End exercise 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbolic forward pass\n",
    "In the previous section you have seen how to create symbolic Theano functions\n",
    "with shared parameters. You have thus all you need to implement the whole\n",
    "forward pass of a generic MLP in Theano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.3\n",
    "\n",
    "#### Begin Exercise 5.3\n",
    "\n",
    "Complete the method **```_forward()```** inside of the **```lxmls/deep\\_learning/mlp.py```**, in the class TheanoMLP.\n",
    "\n",
    "Note that this is called only once at the initialization of the\n",
    "class. To debug your implementation put a breakpoint at the \\_\\_init\\_\\_\n",
    "function call. Hint: Note that this is very similar to NumpyMLP.forward().\n",
    "You just need to keep track of the symbolic variable representing the output of\n",
    "the network after each layer is applied and compile the function at the end.\n",
    "After you are finished instantiate a Theano class and check that Numpy and\n",
    "Theano forward pass are the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxmls.deep_learning import mlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_a = mlp.NumpyMLP(geometry, actvfunc)\n",
    "mlp_b = mlp.TheanoMLP(geometry, actvfunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Exercise 5.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbolic differentiation\n",
    "In the previous section we compiled the forward pass of a MLP. In this section\n",
    "we will do the same with the cost used for training. We will also derive the\n",
    "gradients although this will be trivial once we have the cost function compiled.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.4\n",
    "\n",
    "We first see an example that does not use any of the code in TheanoMLP but\n",
    "rather continues from what you wrote in exercise 6.3. In this exercise you\n",
    "completed a sigmoid layer with Theano. To get some values for the weights we\n",
    "used the first layer of the network you trained in 6.2. now we are going to use\n",
    "the second layer as well. This is thus assuming that your network in 6.2 has\n",
    "only two layers e.g. the recommended geometry (I, 20, 2). Make sure this is the\n",
    "case before starting this exercise.  \n",
    "\n",
    "For the sake of clarity, lets write here the part of Ex. 5.2 that we had completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the values from our MLP from Ex 6.2\n",
    "W1, b1   = mlp_a.params[:2]     # Weights and bias of fist layer \n",
    "# First layer symbolic variables\n",
    "_x  = T.matrix('x')\n",
    "_W1 = theano.shared(value=W1, name='W1', borrow=True) \n",
    "_b1 = theano.shared(value=b1, name='b1', borrow=True, broadcastable=(False, True)) \n",
    "# First layer symbolic expressions\n",
    "_z1       = T.dot(_W1, _x) + _b1\n",
    "_tilde_z1 = T.nnet.sigmoid(_z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "X = np.array([[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]])\n",
    "\n",
    "Y = np.array([0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_1_shape = (2,3)\n",
    "W_2_shape = (3,2)\n",
    "\n",
    "W_1 = np.random.normal(loc=0,scale=0.1, size=W_1_shape)\n",
    "b_1 = np.zeros(3)\n",
    "\n",
    "W_2 = np.random.normal(loc=0,scale=0.1, size=W_2_shape)\n",
    "b_2 = np.zeros(2)\n",
    "\n",
    "weights = [W_1, W_2]\n",
    "biases = [b_1,b_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class activation_layer(object):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    z = np.array(z)\n",
    "    return z*(z>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu([5,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax (z):\n",
    "    return np.exp(z)/np.sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.98201379,  0.01798621])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.array([5,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations = [relu, softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class CrossEntropy(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"\\nTraining cost: CrossEntropy \")\n",
    "\n",
    "    def compute_cost(self, pred, target):\n",
    "        \"\"\"\n",
    "        Return the cost associated for \"Xpred\" and desired output \"Xtarget\".\n",
    "        Note that the function is vectorized and\n",
    "           - rows in pred are training examples. \n",
    "           - rows in target are output predictions\n",
    "\n",
    "        \"\"\"\n",
    "        return np.mean((target - pred)**2)\n",
    "\n",
    "    def delta(self, preactivation, activation, target):\n",
    "        \"\"\"\n",
    "        Return the error delta from the output layer.\n",
    "        \"\"\"\n",
    "        # nablaC_activation = (activation-target)\n",
    "        delta = 0.5 * (activation - target) #* sigmoid_prime(preactivation)\n",
    "        return delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training cost: MSE \n"
     ]
    }
   ],
   "source": [
    "mse = MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(x, weights, biases, activations):\n",
    "    \"\"\"\n",
    "    Computes the activations of the first hidden layer and output layer.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    \n",
    "    z_1 = np.dot(x,W1) + b_1\n",
    "    z_1_tilde = act1(z1)\n",
    "    activations.append(z_1_tilde )\n",
    "    \n",
    "    z_2 = np.dot(z_1_tilde, W2) + b_2\n",
    "    z_2_tilde =  act2(z_2)\n",
    "    activations.append(z_2_tilde)\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_grad(activations, target, cost):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    output = activations[-1]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
